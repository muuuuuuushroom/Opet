import gradio as gr
import torch
import argparse
from PIL import Image
from models import build_model

from util.custom_log import *
import os
import torchvision.transforms as standard_transforms
import cv2
import numpy as np
from util.misc import nested_tensor_from_tensor_list 
import zipfile
import tempfile
from pathlib import Path
import shutil
import pandas as pd

import time
import uuid

# CFG='pretrained/config.yaml'
# CKPT='pretrained/best_checkpoint.pth'
CFG='outputs/WuhanMetro/base_pet/config.yaml'
CKPT='outputs/WuhanMetro/base_pet/best_checkpoint.pth'

global_model = None
global_args = None
global_transform = None  
global_criterion = None

class DeNormalize(object):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __call__(self, tensor):
        for t, m, s in zip(tensor, self.mean, self.std):
            t.mul_(s).add_(m)
        return tensor

def load_model(cfg_path, device, ckpt_path):
    config = load_config(cfg_path)
    args = argparse.Namespace(**config)
    args.resume = ckpt_path
    model, criterion = build_model(args)
    
    if args.resume is None or not os.path.isfile(args.resume):
        raise FileNotFoundError(f"Checkpoint file not found: {args.resume}")
    
    checkpoint = torch.load(args.resume, map_location=device)
    model.load_state_dict(checkpoint['model'])
    model.to(device)
    model.eval()
    return model, args, criterion

def initialize_model(cfg_path, checkpoint_path):
    global global_model, global_args, global_transform, global_criterion
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    global_model, global_args, global_criterion = load_model(cfg_path, device, checkpoint_path)
    # dataset = build_soy(image_set='val', args=global_args)
    # global_transform = None  # dataset.transform
    print('Model and dataset loaded successfully')
    
def _maybe_free_infer_cuda_memory():
    """é‡Šæ”¾æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶æ˜¾å­˜ç¼“å­˜ï¼›ä¸å½±å“å·²åŠ è½½çš„modelå¸¸é©»æ˜¾å­˜ã€‚"""
    if torch.cuda.is_available():
        try:
            torch.cuda.empty_cache()
            # å¯é€‰ï¼šæ›´æ¿€è¿›çš„å›æ”¶ï¼ˆé€šå¸¸ä¸å¿…ï¼Œä½†ä½ å·²æœ‰åœ¨OOMé‡Œç”¨å®ƒï¼‰
            torch.cuda.ipc_collect()
        except Exception:
            pass

def visualization(samples, pred, vis_dir):
    """
    Visualize predictions
    """
    pil_to_tensor = standard_transforms.ToTensor()

    restore_transform = standard_transforms.Compose([
        DeNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        standard_transforms.ToPILImage()
    ])

    images = samples.tensors
    masks = samples.mask
    for idx in range(images.shape[0]):
        sample = restore_transform(images[idx])
        sample = pil_to_tensor(sample.convert('RGB')).numpy() * 255
        sample_vis = sample.transpose([1, 2, 0])[:, :, ::-1].astype(np.uint8).copy()
        h, w = sample_vis.shape[:2]
        # draw ground-truth points (red)
        size = 3
        # draw predictions
        for p in pred[idx]:
            sample_vis = cv2.circle(sample_vis, (int(p[1]), int(p[0])), size, (0, 255, 0), -1)
            
        # save image
        if vis_dir is not None:
            # eliminate invalid area
            imgH, imgW = masks.shape[-2:]
            valid_area = torch.where(~masks[idx])
            valid_h, valid_w = valid_area[0][-1], valid_area[1][-1]
            sample_vis = sample_vis[:valid_h+1, :valid_w+1]

            cv2.imwrite(os.path.join(vis_dir, 'single/example.jpg'), sample_vis)

def _handle_oom(e: Exception, context: str):
    if torch.cuda.is_available():
        try:
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        except Exception:
            pass
    raise gr.Error(f"{context}ï¼šCUDA OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰ã€‚è¯·å°è¯•æ¢å°å›¾ã€‚åŸå§‹ä¿¡æ¯ï¼š{e}")

def predict(image, session_dir: str, history: list):
    """
    Gradio inputs:
      - image: gr.Image(type="filepath")
      - session_dir: gr.State(str)
      - history: gr.State(list)
    Returns:
      - out_img_path
      - out_txt
      - updated history
      - updated dataframe rows
    """
    global global_model, global_args, global_transform, global_criterion
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    if not image or not isinstance(image, str) or not os.path.isfile(image):
        raise gr.Error("è¯·å…ˆä¸Šä¼ å›¾ç‰‡ã€‚")

    if not session_dir:
        # å…œåº•ï¼šæ²¡æœ‰åˆå§‹åŒ– session æ—¶ï¼Œä¸´æ—¶åˆ›å»ºä¸€ä¸ª
        _, session_dir = _new_session()

    # read image
    pil_img = Image.open(image).convert("RGB")
    w, h = pil_img.size
    if max(w, h) > 3200:
        scale = 1600.0 / float(max(w, h))
        new_w = max(1, int(round(w * scale)))
        new_h = max(1, int(round(h * scale)))
        pil_img = pil_img.resize((new_w, new_h), resample=Image.BILINEAR)

    pil_to_tensor = standard_transforms.ToTensor()
    tensor_image = pil_to_tensor(pil_img)

    normalize = standard_transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
    tensor_image = normalize(tensor_image).to(device)
    samples = nested_tensor_from_tensor_list([tensor_image]).to(device)

    outputs = None
    outputs_scores = None

    try:
        with torch.no_grad():
            outputs = global_model(samples, test=True, targets=None)
            outputs_scores = torch.nn.functional.softmax(outputs['pred_logits'], -1)[:, :, 1][0]

        predict_cnt = int(len(outputs_scores))
        out_txt = f"è®¡æ•°å€¼ï¼š {predict_cnt}"

        # å¯è§†åŒ–ï¼ˆå…ˆç”Ÿæˆæœ¬æ¬¡è¾“å‡ºå›¾ï¼‰
        vis_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        pred_points = outputs.get("pred_points", None)

        img_h, img_w = samples.tensors.shape[-2:]
        if pred_points is not None:
            pts = pred_points[0]
            pts = [[pt[0] * img_h, pt[1] * img_w] for pt in pts]
            if isinstance(pts, torch.Tensor):
                pts = pts.detach().cpu().numpy()
            for p in pts:
                vis_bgr = cv2.circle(vis_bgr, (int(p[1]), int(p[0])), 3, (0, 0, 255), -1)

        # === session ç¼“å­˜ï¼šæŒ‰ç¼–å·ä¿å­˜è¾“å…¥/è¾“å‡º ===
        idx = len(history or [])
        sess_dir = Path(session_dir)
        _ensure_dir(sess_dir)

        src_path = Path(image)
        orig_stem = src_path.stem
        orig_suffix = src_path.suffix.lower() or ".jpg"
        
        in_dst = sess_dir / f"{orig_stem}{orig_suffix}"
        out_dst = sess_dir / f"{orig_stem}_pred{predict_cnt}.jpg"
        
        k = 1
        while in_dst.exists() or out_dst.exists():
            in_dst = sess_dir / f"{orig_stem}_{k}{orig_suffix}"
            out_dst = sess_dir / f"{orig_stem}_{k}_pred{predict_cnt}.jpg"
            k += 1

        in_path_saved = _safe_copy(image, in_dst)
        cv2.imwrite(str(out_dst), vis_bgr)
        out_path_saved = str(out_dst)

        item = {
            "idx": idx,
            "ts": _now_tag(),
            "in_img": in_path_saved,
            "out_img": out_path_saved,
            "out_text": out_txt,
            # "in_name": src_path.name, 
        }
        history = _append_history(history, item, limit=50)
        history_df = _history_rows(history)
        gallery_items = [it.get("out_img") for it in (history or []) if it.get("out_img")]

        return out_path_saved, out_txt, history, history_df, gallery_items

    except torch.cuda.OutOfMemoryError as e:
        _handle_oom(e, "å•å›¾æ¨ç†å¤±è´¥")
    except RuntimeError as e:
        if "out of memory" in str(e).lower():
            _handle_oom(e, "å•å›¾æ¨ç†å¤±è´¥")
        raise
    finally:
        try:
            del samples, tensor_image
        except Exception:
            pass
        try:
            del outputs
        except Exception:
            pass
        try:
            del outputs_scores
        except Exception:
            pass
        _maybe_free_infer_cuda_memory()

def _count_from_pil(pil_img: Image.Image) -> int:
    global global_model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    pil_to_tensor = standard_transforms.ToTensor()
    # If resolution too large (e.g., >3000x3000), downsample longest side to 1600 while keeping aspect ratio
    w, h = pil_img.size
    if max(w, h) > 3200:
        scale = 1600.0 / float(max(w, h))
        new_w = max(1, int(round(w * scale)))
        new_h = max(1, int(round(h * scale)))
        pil_img = pil_img.resize((new_w, new_h), resample=Image.BILINEAR)

    tensor_image = pil_to_tensor(pil_img.convert("RGB"))

    normalize = standard_transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
    tensor_image = normalize(tensor_image).to(device)
    samples = nested_tensor_from_tensor_list([tensor_image]).to(device)

    outputs = None
    pts = None
    try:
        with torch.no_grad():
            outputs = global_model(samples, test=True, targets=None)
        img_h, img_w = samples.tensors.shape[-2:]
        pred_points = outputs.get("pred_points", None)
        if pred_points is not None:
            _pts = pred_points[0]
            pts = [[pt[0]*img_h, pt[1]*img_w] for pt in _pts]
        return outputs, pts
    finally:
        # åªæ¸…ç†è¾“å…¥/ä¸­é—´å˜é‡ï¼›outputsè¦è¿”å›ç»™ä¸Šå±‚å°±ä¸delå®ƒ
        try:
            del samples, tensor_image
        except Exception:
            pass
        _maybe_free_infer_cuda_memory()

def predict_zip(zip_path):
    """
    Gradio inputs: gr.File -> `zip_path` typically is a tempfile.NamedTemporaryFile-like.
    Returns:
      - excel filepath (.xlsx)
      - visualizations zip filepath (.zip)
      - dataframe rows: [[filename, count], ...]
    """
    if hasattr(zip_path, "name"):
        zip_path = zip_path.name

    if not isinstance(zip_path, str) or not os.path.isfile(zip_path):
        return None, None, []

    if not zip_path.lower().endswith(".zip"):
        return None, None, []

    exts = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff", ".webp"}

    base_vis_dir = Path("./visualizations_cache/from_zips")
    if base_vis_dir.exists():
        for p in base_vis_dir.iterdir():
            if p.is_file():
                p.unlink()
            elif p.is_dir():
                shutil.rmtree(p)
    base_vis_dir.mkdir(parents=True, exist_ok=True)

    rows = []
    total = 0
    oom_count = 0
    with tempfile.TemporaryDirectory(prefix="gr_zip_") as tmpdir:
        try:
            with zipfile.ZipFile(zip_path, "r") as zf:
                zf.extractall(tmpdir)
        except Exception as e:
            return None, None, []

        files = [p for p in Path(tmpdir).rglob("*") if p.is_file() and p.suffix.lower() in exts]
        files.sort(key=lambda p: str(p).lower())

        if not files:
            return None, None, []

        for p in files:
            outputs = None
            outputs_scores = None
            pil_img = None
            pts = None
            try:
                pil_img = Image.open(str(p)).convert("RGB")
                outputs, pts = _count_from_pil(pil_img)
                outputs_scores = torch.nn.functional.softmax(outputs['pred_logits'], -1)[:, :, 1][0]

                cnt = int(len(outputs_scores))
                
                stem = Path(p.name).stem
                out_name = f"{stem}_pred{cnt}.jpg"
                out_path = base_vis_dir / out_name
                k = 1
                while out_path.exists():
                    out_name = f"{stem}_pred{cnt}_{k}.jpg"
                    out_path = base_vis_dir / out_name
                    k += 1
                
                # visualization
                vis_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                if pts is not None:
                    if isinstance(pts, torch.Tensor):
                        pts = pts.detach().cpu().numpy()
                    for pt in pts:
                        vis_bgr = cv2.circle(vis_bgr, (int(pt[1]), int(pt[0])), 3, (0, 0, 255), -1)
                cv2.imwrite(str(out_path), vis_bgr)

                rows.append([p.name, cnt])
                total += cnt
            except torch.cuda.OutOfMemoryError:
                oom_count += 1
                if torch.cuda.is_available():
                    try:
                        torch.cuda.empty_cache()
                        torch.cuda.ipc_collect()
                    except Exception:
                        pass
                rows.append([p.name, "OOM: æ˜¾å­˜ä¸è¶³"])
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    oom_count += 1
                    if torch.cuda.is_available():
                        try:
                            torch.cuda.empty_cache()
                            torch.cuda.ipc_collect()
                        except Exception:
                            pass
                    rows.append([p.name, "OOM: æ˜¾å­˜ä¸è¶³"])
                else:
                    rows.append([p.name, f"å¤±è´¥: {e}"])
            except Exception as e:
                rows.append([p.name, f"å¤±è´¥: {e}"])
            finally:
                # æ¯å¼ å›¾æ¨ç†ç»“æŸå°±æ¸…ç†ä¸€æ¬¡ï¼Œé¿å…æ‰¹é‡ç´¯ç§¯æ˜¾å­˜ç¢ç‰‡/ç¼“å­˜
                try:
                    del outputs_scores
                except Exception:
                    pass
                try:
                    del outputs
                except Exception:
                    pass
                _maybe_free_infer_cuda_memory()

    # Export Excel
    excel_path = str(base_vis_dir / "counts.xlsx")
    try:
        df = pd.DataFrame(rows, columns=["æ–‡ä»¶å", "è®¡æ•°/çŠ¶æ€"])
        df.to_excel(excel_path, index=False)
    except Exception as e:
        excel_path = None
        rows.append(["__export__", f"Excelå¯¼å‡ºå¤±è´¥: {e}"])

    # Export visualization zip
    vis_zip_path = str(base_vis_dir / "visualizations.zip")
    try:
        with zipfile.ZipFile(vis_zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            for imgp in sorted(base_vis_dir.glob("*.jpg")):
                zf.write(str(imgp), arcname=imgp.name)
    except Exception as e:
        vis_zip_path = None
        rows.append(["__export__", f"å¯è§†åŒ–æ‰“åŒ…å¤±è´¥: {e}"])

    return  excel_path, vis_zip_path, rows

def _now_tag() -> str:
    return time.strftime("%Y.%m.%d-%H.%M.%S")

def _ensure_dir(p: Path) -> Path:
    p.mkdir(parents=True, exist_ok=True)
    return p

def _safe_copy(src: str, dst: Path) -> str:
    """å¤åˆ¶æ–‡ä»¶åˆ°æŒ‡å®šä½ç½®å¹¶è¿”å›æ–°è·¯å¾„ï¼›å°½é‡ä¿ç•™å…ƒä¿¡æ¯ã€‚"""
    _ensure_dir(dst.parent)
    shutil.copy2(src, dst)
    return str(dst)

def _session_root() -> Path:
    # æ¯æ¬¡æ‰“å¼€é¡µé¢ç”Ÿæˆä¸€ä¸ª session_idï¼›å†å²ä»…å¯¹æœ¬æ¬¡è®¿é—®æœ‰æ•ˆ
    return Path("visualizations_cache") / "sessions"

def _new_session() -> tuple[str, str]:
    session_id = uuid.uuid4().hex
    session_dir = _session_root() / session_id
    _ensure_dir(session_dir)
    return session_id, str(session_dir)

def _clear_session_dir(session_dir: str):
    try:
        shutil.rmtree(session_dir, ignore_errors=True)
    except Exception:
        pass

def _append_history(history: list, item: dict, limit: int = 50) -> list:
    history = (history or []) + [item]
    if len(history) > limit:
        history = history[-limit:]
    return history

def _history_rows(history: list) -> list[list[str]]:
    # Dataframe å±•ç¤ºï¼šç¼–å·ã€æ—¶é—´ã€æ–‡ä»¶åã€è®¡æ•°æ‘˜è¦
    rows = []
    for i, it in enumerate(history or []):
        in_name = os.path.basename(it.get("in_img", "") or "")
        rows.append([str(i), it.get("ts", ""), in_name, it.get("out_text", "")])
    return rows

def _on_history_select(evt: gr.SelectData, history: list):
    """
    ç‚¹å‡»å†å²è¡Œï¼šå›å¡« in_img/out_img/out_txt
    Dataframe çš„ evt.index é€šå¸¸æ˜¯ (row, col)
    """
    if not history:
        return gr.update(), gr.update(), gr.update()

    idx = evt.index
    if isinstance(idx, (tuple, list)):
        idx = idx[0]
    try:
        idx = int(idx)
    except Exception:
        return gr.update(), gr.update(), gr.update()

    if idx < 0 or idx >= len(history):
        return gr.update(), gr.update(), gr.update()

    it = history[idx]
    return it.get("in_img"), it.get("out_img"), it.get("out_text")

def _on_history_gallery_select(evt: gr.SelectData, history: list):
    """
    ç‚¹å‡» Galleryï¼ševt.index é€šå¸¸æ˜¯ int
    """
    if not history:
        return gr.update(), gr.update(), gr.update()

    idx = evt.index
    try:
        idx = int(idx)
    except Exception:
        return gr.update(), gr.update(), gr.update()

    if idx < 0 or idx >= len(history):
        return gr.update(), gr.update(), gr.update()

    it = history[idx]
    return it.get("in_img"), it.get("out_img"), it.get("out_text")


def export_single_history(session_dir: str, history: list):
    """
    å¯¼å‡ºæœ¬æ¬¡ä¼šè¯å•å›¾å†å²ï¼š
      - counts.xlsx: è¾“å…¥æ–‡ä»¶åã€è®¡æ•°/çŠ¶æ€ï¼ˆä» out_text è§£æï¼‰
      - visualizations.zip: å†å²é¢„æµ‹è¾“å‡ºå›¾ï¼ˆout_imgï¼‰
    Returns: (excel_path, zip_path)
    """
    if not session_dir:
        return None, None
    if not history:
        raise gr.Error("æœ¬æ¬¡ä¼šè¯è¿˜æ²¡æœ‰å†å²è®°å½•ï¼Œæ— æ³•å¯¼å‡ºã€‚")

    sess_dir = Path(session_dir)
    _ensure_dir(sess_dir)

    # 1) Excel
    rows = []
    for it in (history or []):
        in_name = os.path.basename(it.get("in_img", "") or "")
        out_text = (it.get("out_text", "") or "").strip()

        # ä» "è®¡æ•°å€¼ï¼š X" é‡Œè§£ææ•°å­—ï¼Œè§£æå¤±è´¥å°±åŸæ ·å†™
        cnt_val = out_text
        try:
            # å…¼å®¹ä¸­æ–‡å†’å·/è‹±æ–‡å†’å·
            s = out_text.replace("ï¼š", ":")
            if ":" in s:
                cnt_val = s.split(":", 1)[1].strip()
        except Exception:
            pass

        rows.append([in_name, cnt_val, it.get("ts", ""), it.get("out_img", "")])

    excel_path = str(sess_dir / "single_history_counts.xlsx")
    try:
        df = pd.DataFrame(rows, columns=["è¾“å…¥æ–‡ä»¶", "è®¡æ•°/çŠ¶æ€", "æ—¶é—´", "è¾“å‡ºå›¾è·¯å¾„"])
        df.to_excel(excel_path, index=False)
    except Exception as e:
        raise gr.Error(f"Excelå¯¼å‡ºå¤±è´¥ï¼š{e}")

    # 2) zip å¯è§†åŒ–
    zip_path = str(sess_dir / "single_history_visualizations.zip")
    try:
        with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            added = 0
            for it in (history or []):
                out_img = it.get("out_img")
                if out_img and os.path.isfile(out_img):
                    # åªæŠŠæ–‡ä»¶åæ”¾è¿›å‹ç¼©åŒ…
                    zf.write(out_img, arcname=os.path.basename(out_img))
                    added += 1
        if added == 0:
            # ä»è¿”å›zipï¼Œä½†æç¤ºæ›´æ˜ç¡®
            raise gr.Error("å†å²é‡Œæ²¡æœ‰æ‰¾åˆ°å¯æ‰“åŒ…çš„è¾“å‡ºå›¾åƒæ–‡ä»¶ã€‚")
    except gr.Error:
        raise
    except Exception as e:
        raise gr.Error(f"å¯è§†åŒ–æ‰“åŒ…å¤±è´¥ï¼š{e}")

    return excel_path, zip_path


USER_CREDENTIALS = {"admin": "654321"}

def check_login(username, password):
    """éªŒè¯ç™»å½•ä¿¡æ¯"""
    if username in USER_CREDENTIALS and USER_CREDENTIALS[username] == password:
        return True, "ç™»å½•æˆåŠŸï¼"
    else:
        return False, "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯ï¼"

def gradio_demo():

    candidate_example_files = [
        "visualizations_cache/test_samples/2025.1.5_2025.1.5-1_17-2.jpg",
        "visualizations_cache/test_samples/2025.1.5_2025.1.5-1_24S3000-1-3.jpg",
        "visualizations_cache/test_samples/2025.1.5_2025.1.5-3_17-3.jpg",
        "visualizations_cache/test_samples/24S2982-1-1.jpg",
        "visualizations_cache/test_samples/LZX212-3.jpg"
    ]
    single_examples = [[p] for p in candidate_example_files if os.path.isfile(p)]

    candidate_zip_files = [
        "visualizations_cache/test_samples/test.zip",
    ]
    zip_examples = [[p] for p in candidate_zip_files if os.path.isfile(p)]
    watermark_css = """
            #login_section, #main_section {
                position: relative;
            }
            .gradio-container {
                background-image: none !important;
            }

            /* login/main å…±ç”¨æ°´å°æ ·å¼ */
            #login_section .watermark,
            #main_section .watermark {
                position: absolute;
                top: 0;
                right: 0;
                height: calc(2.6em + 1.2em + 12px);  /* çº¦ç­‰äºä¸¤è¡ŒMarkdownæ ‡é¢˜é«˜åº¦ + é—´è· */
                width: auto;
                z-index: 5;
                pointer-events: none;
                display: flex;
                align-items: flex-start;
                justify-content: flex-end;
            }

            #login_section .watermark img,
            #main_section .watermark img {
                height: 100%;
                width: auto;
                object-fit: contain;
                display: block;
            }
        """
    with gr.Blocks(title="å¤§è±†èƒå›Šè™«è®¡æ•°", css=watermark_css) as demo:
        logo_abs = os.path.abspath("visualizations_cache/logos/logo.png")
        session_id_state = gr.State(value=None)
        session_dir_state = gr.State(value=None)
        single_history_state = gr.State(value=[])

        
        def _init_session():
            sid, sdir = _new_session()
            _clear_session_dir(sdir)
            os.makedirs(sdir, exist_ok=True)
            return sid, sdir, [], [], []
        
        with gr.Column(visible=True, elem_id="login_section") as login_section:
            # åœ¨ç™»å½•åŒºå†…æ”¾ä¸€ä¸ªç»å¯¹å®šä½çš„æ°´å°ï¼ˆé«˜åº¦ç”±CSSæ§åˆ¶ä¸ºâ€œä¸¤è¡ŒMarkdowné«˜åº¦â€ï¼‰
            gr.HTML(f'<div class="watermark"><img src="file={logo_abs}" /></div>')
            gr.Markdown("# ğŸ” å¤§è±†èƒå›Šè™«è®¡æ•°ç³»ç»Ÿ")
            gr.Markdown("### è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨ç³»ç»Ÿ")
            
            with gr.Row():
                username = gr.Textbox(
                    label="ç”¨æˆ·å",
                    value="admin",  # é»˜è®¤ç”¨æˆ·å
                    placeholder="è¾“å…¥ç”¨æˆ·å",
                    scale=2
                )
            with gr.Row():
                password = gr.Textbox(
                    label="å¯†ç ",
                    type="password",
                    value="",  # é»˜è®¤å¯†ç 
                    placeholder="è¾“å…¥å¯†ç ",
                    scale=2
                )

            with gr.Row():
                login_btn = gr.Button("ç™»å½•", variant="primary", size="lg")
                clear_btn = gr.Button("æ¸…é™¤", size="lg")

            login_status = gr.Textbox(label="ç™»å½•çŠ¶æ€", visible=False)

        # ä¸»åº”ç”¨ç•Œé¢ï¼ˆåˆå§‹éšè—ï¼‰
        with gr.Column(visible=False, elem_id="main_section") as main_section:
            gr.HTML(f'<div class="watermark"><img src="file={logo_abs}" /></div>')
            gr.Markdown("# ğŸŒ± å¤§è±†èƒå›Šè™«è®¡æ•°")
            gr.Markdown("### è¯·é€‰æ‹©å•å›¾æ¨ç†æˆ–æ‰¹é‡å¤„ç†æ•°æ®")
            

            with gr.Tab("å•å›¾ç²¾ç»†åŒ–ç‚¹å›å½’è®¡æ•°"):
                with gr.Row():
                    with gr.Column(scale=1):
                        in_img = gr.Image(
                            type="filepath",
                            label="ä¸Šä¼ å›¾ç‰‡",
                            height=None,
                            width=None
                        )
                    with gr.Column(scale=1):
                        out_img = gr.Image(
                            type="filepath",
                            label="é¢„æµ‹ç»“æœ",
                            height=None,
                            width=None
                        )
                with gr.Row():
                    clear_btn_main = gr.Button("æ¸…é™¤")
                    submit_btn = gr.Button("æäº¤", variant="primary")

                with gr.Row():
                    out_txt = gr.Textbox(label="ç»Ÿè®¡ä¿¡æ¯", lines=1)

                # ä¸€é”®ä¾‹å­ï¼ˆç‚¹ä¸€ä¸‹è‡ªåŠ¨æŠŠä¾‹å›¾å¡«å…¥è¾“å…¥æ¡†ï¼‰
                if single_examples:
                    gr.Examples(
                        examples=single_examples,
                        inputs=[in_img],
                        label="å•å›¾æµ‹è¯•ç”¨ä¾‹"
                    )
                single_history_gallery = gr.Gallery(
                    label="å†å²é¢„æµ‹è¾“å‡ºï¼ˆç‚¹å‡»å›å¡«ï¼‰",
                    columns=5,
                    height=300, 
                    show_label=True,
                    allow_preview=True,
                    object_fit="contain", 
                    )
                single_history_df = gr.Dataframe(
                    headers=["åºå·", "æ—¶é—´", "è¾“å…¥æ–‡ä»¶", "è®¡æ•°è¾“å‡º"],
                    value=[],
                    interactive=False,
                    row_count=(0, "dynamic"),
                    col_count=(4, "fixed"),
                    label="å†å²é¢„æµ‹ï¼ˆç‚¹å‡»å›å¡«ï¼‰",
                    wrap=True,
                    height=280
                    )

                
                demo.load(
                        _init_session,
                        inputs=None,
                        outputs=[
                            session_id_state,
                            session_dir_state,
                            single_history_state,
                            single_history_df,
                            single_history_gallery,
                        ],
                    )
                single_history_df.select(
                    fn=_on_history_select,
                    inputs=[single_history_state],
                    outputs=[in_img, out_img, out_txt],
                    )
                single_history_gallery.select(
                    fn=_on_history_gallery_select,
                    inputs=[single_history_state],
                    outputs=[in_img, out_img, out_txt],
                    )

                
                submit_btn.click(
                    fn=predict,
                    inputs=[in_img, session_dir_state, single_history_state],
                    outputs=[out_img, out_txt, single_history_state, single_history_df, single_history_gallery],
                    )
                clear_btn_main.click(
                    fn=lambda: [None, None, [], [], []],
                    inputs=None,
                    outputs=[in_img, out_img, single_history_state, single_history_df, single_history_gallery],
                    )
                with gr.Row():
                    export_single_btn = gr.Button("å¯¼å‡ºå†å²è®°å½•", variant="primary")

                with gr.Row():
                    single_out_excel = gr.File(label="å†å²è®°å½•æŠ¥è¡¨")
                    single_out_viszip = gr.File(label="å†å²è®°å½•å¯è§†åŒ–")

            with gr.Tab("é«˜é€šé‡æ‰¹é‡å›¾åƒåˆ†æ"):
                zip_in = gr.File(label="ä¸Šä¼  .zip å‹ç¼©åŒ…æ–‡ä»¶", file_types=[".zip"])
                batch_btn = gr.Button("å¼€å§‹æ‰¹é‡è®¡æ•°", variant="primary")

                with gr.Row():
                    out_excel = gr.File(label="å¯¼å‡ºè®¡æ•°æŠ¥è¡¨")
                    out_viszip = gr.File(label="ä¸‹è½½æ‰€æœ‰å¯è§†åŒ–")

                out_table = gr.Dataframe(headers=["æ–‡ä»¶å", "è®¡æ•°/çŠ¶æ€"], label="ç»“æœ", wrap=True)

                # ä¸€é”®ä¾‹å­ï¼ˆç‚¹ä¸€ä¸‹è‡ªåŠ¨æŠŠzipå¡«å…¥è¾“å…¥æ¡†ï¼‰
                if zip_examples:
                    gr.Examples(
                        examples=zip_examples,
                        inputs=[zip_in],
                        label="æ‰¹é‡æµ‹è¯•ç”¨ä¾‹"
                    )

                batch_btn.click(
                    fn=predict_zip,
                    inputs=[zip_in],
                    outputs=[out_excel, out_viszip, out_table]
                )
                


            # æ·»åŠ é€€å‡ºç™»å½•æŒ‰é’®
            with gr.Row():
                logout_btn = gr.Button("é€€å‡ºç™»å½•", variant="secondary")

        # ç™»å½•æŒ‰é’®äº‹ä»¶
        def login_action(username, password):
            success, message = check_login(username, password)
            if success:
                return [
                    gr.update(visible=False),  # éšè—ç™»å½•ç•Œé¢
                    gr.update(visible=True),   # æ˜¾ç¤ºä¸»ç•Œé¢
                    gr.update(value=message, visible=True)
                ]
            else:
                try:
                    gr.Warning(message)
                except Exception:
                    pass

                return [
                    gr.update(visible=True),
                    gr.update(visible=False),
                    gr.update(value=message, visible=True)
                ]

        # æ¸…é™¤æŒ‰é’®äº‹ä»¶
        def clear_login():
            return [
                gr.update(value="admin"),
                gr.update(value=""),
                gr.update(visible=False)
            ]

        # é€€å‡ºç™»å½•äº‹ä»¶
        def logout_action():
            return [
                gr.update(visible=True),   # æ˜¾ç¤ºç™»å½•ç•Œé¢
                gr.update(visible=False),  # éšè—ä¸»ç•Œé¢
                gr.update(value="", visible=False)
            ]

        # ç»‘å®šäº‹ä»¶
        login_btn.click(
            fn=login_action,
            inputs=[username, password],
            outputs=[login_section, main_section, login_status]
        )

        clear_btn.click(
            fn=clear_login,
            inputs=None,
            outputs=[username, password, login_status]
        )

        logout_btn.click(
            fn=logout_action,
            inputs=None,
            outputs=[login_section, main_section, login_status]
        )
        
        export_single_btn.click(
            fn=export_single_history,
            inputs=[session_dir_state, single_history_state],
            outputs=[single_out_excel, single_out_viszip],
        )

        # å›è½¦é”®ä¹Ÿå¯ä»¥è§¦å‘ç™»å½•
        password.submit(
            fn=login_action,
            inputs=[username, password],
            outputs=[login_section, main_section, login_status]
        )

    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        debug=True,
        # allowed_paths=["visualizations_cache"]
    )

if __name__ == "__main__":
    
    initialize_model(
        cfg_path=CFG, 
        checkpoint_path=CKPT
    )
    gradio_demo()